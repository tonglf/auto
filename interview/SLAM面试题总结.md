# SLAM面试题总结

## 深蓝学院

### 2019年秋招题库参考

> source：[视觉SLAM面试题汇总（2019年秋招题库参考）——第一部分](https://zhuanlan.zhihu.com/p/205008396)

**1 SIFT和SUFT的区别**

构建图像金字塔，SIFT特征利用不同尺寸的图像与高斯差分滤波器卷积；SURF特征利用原图片与不同尺寸的方框滤波器卷积。

特征描述子，SIFT特征有4×4×8=128维描述子，SURF特征有4×4×4=64维描述子

特征点检测方法，SIFT特征先进行非极大抑制，再去除低对比度的点，再通过Hessian矩阵去除边缘响应过大的点；SURF特征先利用Hessian矩阵确定候选点，然后进行非极大抑制

特征点主方向，SIFT特征在正方形区域内统计梯度幅值的直方图，直方图最大值对应主方向，可以有多个主方向；SURF特征在圆形区域内计算各个扇形范围内x、y方向的haar小波响应，模最大的扇形方向作为主方向

**2 相似变换、仿射变换、射影变换的区别**

等距变换：相当于是平移变换（t）和旋转变换（R）的复合，等距变换前后长度，面积，线线之间的角度都不变。自由度为6（3+3）

相似变换：等距变换和均匀缩放（S）的一个复合，类似相似三角形，体积比不变。自由度为7（6+1）

仿射变换：一个平移变换（t）和一个非均匀变换（A）的复合，A是可逆矩阵，并不要求是正交矩阵，仿射变换的不变量是:平行线，平行线的长度的比例，面积的比例。自由度为12（9+3）

射影变换：当图像中的点的齐次坐标的一般非奇异线性变换，射影变换就是把理想点（平行直线在无穷远处相交）变换到图像上，射影变换的不变量是:重合关系、长度的交比。自由度为15（16-1）

参考：多视图几何总结——等距变换、相似变换、仿射变换和射影变换

**3 Homography、Essential和Fundamental Matrix的区别**

Homography Matrix可以将一个二维射影空间的点变换该另一个二维射影空间的点，如下图所示，在不加任何限制的情况下，仅仅考虑二维射影空间中的变换，一个单应矩阵H HH可由9个参数确定，减去scale的一个自由度，自由度为8。



![img](https://pic2.zhimg.com/80/v2-bcb5f7e7e41d3f923d61b8b205aa773d_720w.jpg)

Fundamental Matrix对两幅图像中任何一对对应点x和x′基础矩阵F都满足条件：

![img](https://pic1.zhimg.com/80/v2-8294a3b5ff87f3a1b563246fbcba6630_720w.png)

，秩只有2，因此F的自由度为7。它自由度比本质矩阵多的原因是多了两个内参矩阵。

Essential matrix：本质矩是归一化图像坐标下的基本矩阵的特殊形式，其参数由运动的位姿决定，与相机内参无关，其自由度为6，考虑scale的话自由度为5。

参考多视图几何总结——基础矩阵、本质矩阵和单应矩阵的自由度分析

**4 视差与深度的关系**

在相机完成校正后，则有 d/b=f/z,其中d表示视差，b表示基线，f是焦距，z是深度。这个公式其实很好记，在深度和焦距确定的情况下，基线越大，视差也会越大。



![img](https://pic2.zhimg.com/80/v2-c42354f0ecf11f3cd8f2026fddf9c3f5_720w.jpg)

**5 描述PnP算法**

已知空间点世界坐标系坐标和其像素投影，公式如下

![img](https://pic4.zhimg.com/80/v2-19518bcf9fb5f71d769055d50a5a6d8b_720w.jpg)

目前一共有两种解法，直接线性变换方法（一对点能够构造两个线性约束，因此12个自由度一共需要6对匹配点），另外一种就是非线性优化的方法，假设空间坐标点准确，根据最小重投影误差优化相机位姿。

目前有两个主要场景场景，其一是求解相机相对于某2维图像/3维物体的位姿；其二就是SLAM算法中估计相机位姿时通常需要PnP给出相机初始位姿。

在场景1中，我们通常输入的是物体在世界坐标系下的3D点以及这些3D点在图像上投影的2D点，因此求得的是相机坐标系相对于世界坐标系(Twc)的位姿

在场景2中，通常输入的是上一帧中的3D点（在上一帧的相机坐标系下表示的点）和这些3D点在当前帧中的投影得到的2D点，所以它求得的是当前帧相对于上一帧的位姿变换

**6 闭环检测常用方法**

ORB SLAM中采用的是词袋模型进行闭环检测筛选出候选帧，再通过求解Sim3判断最合适的关键帧

LSD SLAM中的闭环检测主要是根据视差、关键帧连接关系，找出候选帧，然后对每个候选帧和测试的关键帧之间进行双向Sim3跟踪，如果求解出的两个李代数满足马氏距离在一定范围内，则认为是闭环成功

**7给一个二值图，求最大连通域**

这个之后单独写一篇博客来研究这个好了，二值图的连通域应该是用基于图论的深度优先或者广度优先的方法，后来还接触过基于图的分割方法，采用的是并查集的数据结构，之后再作细致对比研究。

**8 梯度下降法、牛顿法、高斯-牛顿法的区别**

在BA优化、PnP、直接法里面都有接触到非线性优化问题，上面几种方法都是针对对非线性优化问题提出的方法，将非线性最优化问题作如下展开，就可以获得梯度下降法和牛顿法

![img](https://pic1.zhimg.com/80/v2-92ccea76d5481ab241e7097bf2860258_720w.png)

梯度下降法是一个一阶最优化算法，通常也称为最速下降法。 要使用梯度下降法找到一个函数的局部极小值，必须向函数上当前点对应梯度（或者是近似梯度）的反方向的规定步长距离点进行迭代搜索。因此指保留一阶梯度信息。缺点是过于贪心，容易走出锯齿路线。

![img](https://pic4.zhimg.com/80/v2-237165328c907bf202412156e733cf0f_720w.png)

牛顿法是一个二阶最优化算法，基本思想是利用迭代点处的一阶导数(梯度)和二阶导数(Hessen矩阵)对目标函数进行二次函数近似。因此保留二阶梯度信息。缺点是需要计算H矩阵，计算量太大。

![img](https://pic3.zhimg.com/80/v2-2a43454a053228f6025a15a108a5c8aa_720w.jpg)

而把非线性问题，先进行一阶展开，然后再作平方处理就可以得到高斯-牛顿法和列文博格方法

![img](https://pic4.zhimg.com/80/v2-f4d21334c24bb4aa3a02b98420fd4b0f_720w.jpg)

高斯-牛顿法对上式展开并对Δx进行求导即可得高斯牛顿方程，其实其就是使用

![img](https://pic3.zhimg.com/80/v2-317eb5b46bdfe47b212361321d101506_720w.png)

对牛顿法的H矩阵进行替换，但是

![img](https://pic3.zhimg.com/80/v2-317eb5b46bdfe47b212361321d101506_720w.png)

有可能为奇异矩阵或变态，Δx也会造成结果不稳定，因此稳定性差

![img](https://pic1.zhimg.com/80/v2-aa5449c6487b3ee76d2f68b7cf905e4c_720w.png)

列文博格法就是在高斯-牛顿法的基础上对Δx添加一个信赖区域，保证其只在展开点附近有效，即其优化问题变为带有不等式约束的优化问题，利用Lagrange乘子求解

![img](https://pic3.zhimg.com/80/v2-9586029d1f399e410c18e5df5de35062_720w.jpg)

**9 推导一下卡尔曼滤波、描述下粒子滤波**

用自己的描述下，仅供参考：

卡尔曼滤波：

卡尔曼滤波就是通过运动方程获得均值和方差的预测值，然后结合观测方程和预测的方差求得卡尔曼增益，然后在用卡尔曼增益更行均值和方差的预测值而获得估计值。

卡尔曼滤波推导的思路是（其中一种）先假定有这么一个修正公式

![img](https://pic4.zhimg.com/80/v2-34382b55861aaaf3e7ebdec7dd2235af_720w.png)

构真实值和估计值之间的协方差矩阵，然后通过对对角线元素求和获得方差表达式，我们的修正公式是需要使得方差最小，因此把方差表达式对

![img](https://pic1.zhimg.com/80/v2-28072b4003192af679698ff6eea3f4e8_720w.png)

求导就可以获得卡尔曼增益的表达式，然后从先验到预测值的方差公式可以通过求预测值和真实值的协方差矩阵获得。

粒子滤波：

粒子滤波最常用的是SIR，其算法是用运动方程获得粒子的状态采样，然后用观测方程进行权值更新，通过新的粒子加权平均就获得新的估计状态，最后非常重要的一步就是重采用。

粒子滤波的推导中概念有很多，最重要的推导过程是重要性采样过程，其思路就是我原本的采样分布是不知道的，我如何从一个已知的分布中采样，通过加权的方式使得从已知的分布中采样的粒子分布和原本未知的分布中采样的粒子分布结果一致，从而引入SIS粒子滤波，再进一步加入重采样后就引入了SIR粒子滤波。

具体的可以参看我的另外两个总结博客

概率机器人总结——粒子滤波先实践再推导

概率机器人总结——(扩展)卡尔曼滤波先实践再推导

**10如何求解Ax=b的问题**

参看我的另外一个总结博客多视图几何总结——基础矩阵、本质矩阵和单应矩阵的求解过程

**11 什么是极线约束**

所谓极线约束就是说同一个点在两幅图像上的映射，已知左图映射点p1，那么右图映射点p2一定在相对于p1的极线上，这样可以减少待匹配的点数量。如下图：

![img](https://pic2.zhimg.com/80/v2-bef18d99dbebdc9bdbeeab1512e26a71_720w.jpg)

**12单目视觉SLAM中尺寸漂移是怎么产生的**

用单目估计出来的位移，与真实世界相差一个比例，叫做尺度。这个比例在单目初始化时通过三角化确定，但单纯靠视觉无法确定这个比例到底有多大。由于SLAM过程中噪声的影响，这个比例还不是固定不变的。修正方式是通过回环检测计算Sim3进行修正。

**13解释SLAM中的绑架问题**

绑架问题就是重定位，是指机器人在缺少之前位置信息的情况下，如何去确定当前位姿。例如当机器人被安置在一个已经构建好地图的环境中，但是并不知道它在地图中的相对位置，或者在移动过程中，由于传感器的暂时性功能故障或相机的快速移动，都导致机器人先前的位置信息的丢失，在这种情况下如何重新确定自己的位置。

初始化绑架可以阐述为一种通常状况初始化问题，可使用蒙特卡洛估计器，即粒子滤波方法，重新分散粒子到三维位形空间里面，被里程信息和随机扰动不断更新，初始化粒子聚集到/收敛到可解释观察结果的区域。追踪丢失状态绑架，即在绑架发生之前，系统已经保存当前状态，则可以使用除视觉传感器之外的其他的传感器作为候补测量设备。

**14描述特征点法和直接法的优缺点**

特征点法

优点：1. 没有直接法的强假设，更加精确；2. 相较与直接法，可以在更快的运动下工作，鲁棒性好

缺点：1. 特征提取和特征匹配过程耗时长；2. 特征点少的场景中无法使用；3.只能构建稀疏地图

直接法：

优点：1.省去了特征提取和特征匹配的时间，速度较快；2. 可以用在特征缺失的场合；3. 可以构建半稠密/稠密地图

缺点：1. 易受光照和模糊影响；2.运动必须慢；3.非凸性，易陷入局部极小解

**15EKF和BA的区别**

（1） EKF假设了马尔科夫性，认为k时刻的状态只与k-1时刻有关。BA使用所有的历史数据，做全体的SLAM

（2） EKF做了线性化处理，在工作点处用一阶泰勒展开式近似整个函数，但在工作点较远处不一定成立。BA每迭代一次，状态估计发生改变，我们会重新对新的估计点做泰勒展开，可以把EKF看做只有一次迭代的BA

**16边缘检测算子有哪些？**

边缘检测一般分为三步，分别是滤波、增强、检测。基本原理都是用高斯滤波器进行去噪，之后在用卷积内核寻找像素梯度。常用有三种算法：canny算子，sobel算子，laplacian算子

canny算子：一种完善的边缘检测算法，抗噪能力强，用高斯滤波平滑图像，用一阶偏导的有限差分计算梯度的幅值和方向，对梯度幅值进行非极大值抑制，采用双阈值检测和连接边缘。

sobel算子：一阶导数算子，引入局部平均运算，对噪声具有平滑作用，抗噪声能力强，计算量较大，但定位精度不高，得到的边缘比较粗，适用于精度要求不高的场合。

laplacian算子：二阶微分算子，具有旋转不变性，容易受噪声影响，不能检测边缘的方向，一般不直接用于检测边缘，而是判断明暗变化。

**17 简单实现cv::Mat()**

**18 10个相机同时看到100个路标点，问BA优化的雅克比矩阵多少维**

因为误差对相机姿态的偏导数的维度是2×6,对路标点的偏导数是2×3，又10个相机可以同时看到100个路标点，所以一共有10×100×2行，100×3+10×6个块。

![img](https://pic1.zhimg.com/80/v2-82cbabf256dfbc6b63ac3f4e28a49fc8_720w.png)

**19介绍经典的视觉SLAM框架**

视觉SLAM总结——ORB SLAM2中关键知识点总结

视觉SLAM总结——SVO中关键知识点总结

视觉SLAM总结——LSD SLAM中关键知识点总结

**20介绍下你熟悉的非线性优化库**

非线性优化库一般有ceres和g2o两种，我比较熟悉的是g2o，看下g2o的结构图

![img](https://pic1.zhimg.com/80/v2-c5dc33d30b1f4eb7af4680c02dc075f8_720w.jpg)

它表示了g2o中的类结构。 首先根据前面的代码经验可以发现，我们最终使用的optimizer是一个SparseOptimizer对象，因此我们要维护的就是它(对它进行各种操作)。 一个SparseOptimizer是一个可优化图(OptimizableGraph)，也是一个超图(HyperGraph)。而图中有很多顶点(Vertex)和边(Edge)。顶点继承于BaseVertex，边继承于BaseUnaryEdge、BaseBinaryEdge或BaseMultiEdge。它们都是抽象的基类，实际有用的顶点和边都是它们的派生类。我们用SparseOptimizer.addVertex和SparseOptimizer.addEdge向一个图中添加顶点和边，最后调用SparseOptimizer.optimize完成优化。

在优化之前还需要制定求解器和迭代算法。一个SparseOptimizer拥有一个OptimizationAlgorithm，它继承自Gauss-Newton, Levernberg-Marquardt, Powell’s dogleg三者之一。同时，这个OptimizationAlgorithm拥有一个Solver，它含有两个部分。一个是 SparseBlockMatrix，用于计算稀疏的雅可比和海塞矩阵；一个是线性方程求解器，可从PCG、CSparse、Choldmod三选一，用于求解迭代过程中最关键的一步：

![img](https://pic3.zhimg.com/80/v2-1f8fd9ca2011fafa8879dc494756baea_720w.png)

因此理清了g2o的结构，也就知道了其使用流程。在之前已经说过了，这里就再重复一遍：

（1）选择一个线性方程求解器，PCG、CSparse、Choldmod三选一，来自g2o/solvers文件夹

（2）选择一个BlockSolver，用于求解雅克比和海塞矩阵，来自g2o/core文件夹

（3）选择一个迭代算法，GN、LM、DogLeg三选一，来自g2o/core文件夹

参考G2O图优化基础和SLAM的Bundle Adjustment(光束法平差)

这里我补充下：

注意到上面的结构图中，节点Basevertex<D,T>，BaseBinaryEdge<D,E,VertexXi,VertexXj>和BlockSolver<>等都是模板类，我们可以根据自己的需要初始化不同类型的节点和边以及求解器，以ORB SLAM2为例，分析下后端最典型的全局BA所用的边、节点和求解器：

（1）边是EdgeSE3ProjectXYZ，它其实就是继承自BaseBinaryEdge<2, Vector2d, VertexSBAPointXYZ, VertexSE3Expmap>，其模板类型里第一个参数是观测值维度，这里的观测值是其实就是我们的像素误差u,v u,vu,v，第二个参数就是我们观测值的类型，第三个第四个就是我们边两头节点的类型；

（2）相机节点VertexSE3Expmap，它其实就是继承自BaseVertex<6, SE3Quat>，其模板类第一个参数就是其维度，SE3是六维的这没毛病，第二个就是节点的类型，SE3Quat就是g2o自定义的SE3的类，类里面写了各种SE3的计算法则；

（3）空间点节点VertexSBAPointXYZ，它其实就是继承自BaseVertex<3, Vector3d>，其模板类第一个参数是说明咱空间点的维度是三维，第二个参数说明这个点的类型是Vector3d；

（4）求解器是BlockSolver_6_3，它其实就是BlockSolver< BlockSolverTraits<6, 3> >，6,3分别指代的就是边两边的维度了。

我记得我刚开始学习SLAM的时候自己想办法写后端的时候很纳闷这个图是怎么构建起来的，在ORB或者SVO里面，所有的地图点和关键帧都是以类的形式存在的，例如在ORB中是先将关键帧的节点添加起来，然后添加空间点，然后遍历空间点中记录的与哪些关键帧有关系，然后相应ID的关键帧的节点和空间点的节点连接起来，然后就把图建立起来了，我觉得不写类好像没有什么其他更好的办法了。

**21室内SLAM与自动驾驶SLAM有什么区别？**

这是个开放题，参考无人驾驶技术与SLAM的契合点在哪里，有什么理由能够让SLAM成为无人驾驶的关键技术？

**22 什么是紧耦合、松耦合？优缺点。**

这里默认指的是VIO中的松紧耦合，这里参考深蓝学院的公开课里面介绍：

![img](https://pic2.zhimg.com/80/v2-82b125858ae8035aea08e8623a052031_720w.jpg)

紧耦合是把图像的特征加到特征向量中去，这样做优点是可以免去中间状态的累计误差，提高精度，缺点是系统状态向量的维数会非常高，需要很高的计算量；

松耦合是把VO处理后获得的变换矩阵和IMU进行融合，这样做优点是计算量小但是会带来累计误差。

下面是对经典的VIO框架进行一个分类

![img](https://pic1.zhimg.com/80/v2-bd588deb6aa5b737aa8197241a012c54_720w.jpg)

**23地图点的构建方法有哪些**

（1）在ORB SLAM2中是根据三角化的方法确定地图点的，利用匹配好的两个点构建AX=b的方程，然后利用SVD分解取最小奇异值对应的特征向量作为地图点坐标，参考多视图几何总结——三角形法

（2）在SVO中是利用深度滤波器进行种子点深度更新，当种子点深度收敛后就加入地图构建地图点。

（在LSD中好像没有维护地图点，不断维护的是关键帧上的深度图）

继续补充…

**24 如果对于一个3D点，我们在连续帧之间形成了2D特征点之间的匹配，但是这个匹配中可能存在错误的匹配。请问你如何去构建3D点？**

毋庸置疑首先想到的是用RANSAC方法进行连续帧之间的位姿估计，然后用内点三角化恢复地图点，具体一点说使用RANSAC估计基础矩阵的算法步骤如下：

（1）从匹配的点对中选择8个点，使用8点法估算出基础矩阵F

（2）计算其余的点对到其对应对极线的距离

![img](https://pic1.zhimg.com/80/v2-d9d171ae81896c9aad44fdb44ff42848_720w.png)

，如果

![img](https://pic2.zhimg.com/80/v2-24f1a964b431cb3f3116711a2b9b194d_720w.png)

则该点为内点，否则为外点。记下符合该条件的内点的个数为

![img](https://pic2.zhimg.com/80/v2-43a9a5d0de011bd5ce6b1004cd0706b9_720w.png)



（4）迭代k次，或者某次得到内点的数目

![img](https://pic2.zhimg.com/80/v2-43a9a5d0de011bd5ce6b1004cd0706b9_720w.png)

占有的比例大于等于95%，则停止。选择

![img](https://pic2.zhimg.com/80/v2-43a9a5d0de011bd5ce6b1004cd0706b9_720w.png)

最大的基础矩阵作为最终的结果。如果是利用非线性优化的方法获得位姿的话，可以在

非线性优化代价函数中加入鲁棒核函数来减少无匹配所带来的误差，例如《视觉SLAM十四讲》里面提到的Huber核

![img](https://pic3.zhimg.com/80/v2-1e8e854ccb9ef4d6fa17b8128e73021a_720w.jpg)

在《机器人的状态估计》一书总将这种方法称为M估计，核函数还包裹Cauchy核

![img](https://pic1.zhimg.com/80/v2-75c27b3c220ac468fbed1316fe6b3b64_720w.jpg)

Geman-MeClure核

![img](https://pic1.zhimg.com/80/v2-6aa4ad22668ad172e462daf8ce29a768_720w.png)

等等。

**25 RANSAC在选择最佳模型的时候用的判断准则是什么?**

简单地说一般是选用具有最小残差和的模型作为最佳模型。



> source：[万字干货！视觉SLAM面试题汇总（19年秋招）——第二部分](https://zhuanlan.zhihu.com/p/212264860)

**视觉SLAM总结——视觉SLAM面试题汇总（后26个）**

\26. 除了RANSAC之外，还有什么鲁棒估计的方法？

\27. 3D地图点是怎么存储的？表达方式？

\28. 给你m相机n个点的bundle adjustment。当我们在仿真的时候，在迭代的时候，相机的位姿会很快的接近真值。而地图点却不能很快的收敛这是为什么呢？

\29. LM算法里面那个λ是如何变化的呢？

\30. 说一下3D空间的位姿如何去表达?

\31. 李群和李代数的关系

32.求导

![img](https://pic3.zhimg.com/80/v2-6582b6b0f790156d3e340ce46fe56666_720w.png)



\33. Mat是如何访问元素的？先访问行还是先访问列？

\34. 写出单目相机的投影模型，畸变模型。

\35. 安装2D lidar的平台匀速旋转的时候，去激光数据畸变，写代码

\36. 给两组已经匹配好的3D点，计算相对位姿变换，写代码

\37. ORB-SLAM初始化的时候为什么要同时计算H矩阵和F矩阵？

\38. 说一下Dog-Leg算法

\39. Vins-Mono里面什么是边缘化？First Estimate Jacobian？一致性？可观性？

\40. 说一下VINS-Mono的优缺点

41.导一下VINS-Mono里面的预积分公式

42.给定一些有噪声的GPS信号的时候如何去精准的定位？

43.何标定IMU与相机之间的外参数？

44 给你xx误差的GPS，给你xx误差的惯导你怎么得到一个cm级别的地图?

\45. 计算H矩阵和F矩阵的时候有什么技巧呢？

\46. 给一组点云，从中提取平面。

\47. 给一张图片，知道相机与地面之间的相对关系，计算出图的俯视图。

\48. 双线性插值如何去做，写公式。

\49. RGB-D的SLAM和RGB的SLAM有什么区别？

50.什么是ORB特征? ORB特征的旋转不变性是如何做的? BRIEF算子是怎么提取的?

51.ORB-SLAM中的特征是如何提取的？如何均匀化的？



还是老规矩，先自己想，再看答案哟~^-^

------

**26. 除了RANSAC之外，还有什么鲁棒估计的方法？**

在《机器人的状态估计》一书中还介绍了M估计（广义的最大似然估计）和协方差估计，所谓M估计指的是加入鲁棒代价函数最大似然估计，而**协方差估计**指的是同时估计状态和协方差的方法，也称**自适应估计。**

**27. 3D地图点是怎么存储的？表达方式？**

以ORB SLAM2为例，3D地图点是以类的形式存储的，在类里面除了存储3D地图点的空间点，同时还存储了3D点的描述子（其实就是BRIFE描述子），用来快速进行与特征点的匹配，同时还用一个map存储了与其有观测关系的关键帧以及其在关键帧中的Index等等。

**28. 给你m相机n个点的bundle adjustment。当我们在仿真的时候，在迭代的时候，相机的位姿会很快的接近真值。而地图点却不能很快的收敛这是为什么呢？**

约束相机位姿的方程远多于约束地图点的方程

**29. LM算法里面那个λ是如何变化的呢？**

这里我想从头开始理一遍，参考《视觉SLAM十四讲》首先LM算法优势在哪里，GN法采用雅克比矩阵

![img](https://pic4.zhimg.com/80/v2-b6948450c2510ab67360ae355777f197_720w.png)

的形式来代替难求的海森矩阵，但是

![img](https://pic4.zhimg.com/80/v2-b6948450c2510ab67360ae355777f197_720w.png)

是半正定的，可能出现奇异矩阵或者病态的情况，而且Δx太大的时候也会导致这种二阶泰勒展开的近似不够准确，为解决第二个问题，提出了给Δx添加一个信赖区域方法，也就是LM法，其采用下式判断近似差异的大小进而确定信赖区域范围：

![img](https://pic4.zhimg.com/80/v2-f61bec596738301a098ac3f7c3c2c153_720w.jpg)

其中分析是实际的代价函数下降值，分母是近似下降值。如果ρ越接近1说明近似越准确，ρ过小说明实际下降较小，需要缩小信赖区域范围，如果ρ过大说明实际下降较大，需要扩大信赖区域范围。其步骤如下：

1.初始化

![img](https://pic3.zhimg.com/80/v2-c61a4e24d34a64b8ae1e4225e39ab142_720w.png)

和优化半径μ；

2.进行迭代求解

![img](https://pic2.zhimg.com/80/v2-3fe6a1abbacbf23e1f5e1824e048cbdd_720w.png)

这里D为单位阵是信赖区域范围为一个球形

3.计算ρ

4.如果ρ>3/4，则μ=2μ（扩大信赖区域范围）

5.如果ρ=1/4，则μ=0.5μ（缩小信赖区域范围）

6.如果ρ大于某一阈值，则进行更新

![img](https://pic1.zhimg.com/80/v2-49df150ccc64efebf02ad481b6316ac4_720w.png)

这里面需要优化一个带约束的非线性优化函数，采用拉格朗日乘子法就引入了λ，如下

![img](https://pic2.zhimg.com/80/v2-69a0882486b46819f78e9d8f30a2a3b9_720w.jpg)

求解后获得

![img](https://pic4.zhimg.com/80/v2-7a88d7080250a22c6c9dbe43ce4b3ad3_720w.jpg)

当D=I时有

![img](https://pic4.zhimg.com/80/v2-9c10d5e81ddb5c2d860224fd884d5d4b_720w.png)

求解后当λ较小时说明Δx近似于GN方法求解的结果，二阶是较好的近似，而λ较大时说明近似于一阶梯度下降法，二阶近似效果不够好。

**30. 说一下3D空间的位姿如何去表达?**

李群或者李代数

**31. 李群和李代数的关系**

![img](https://pic3.zhimg.com/80/v2-d8c10d077a0b84bcc3f70bed1d19114e_720w.jpg)

如上图所示（摘自《视觉SLAM十四讲》），从李群到李代数是对数映射，形式上是先取对数，然后取∨，从李代数到李群是**对数映射**，形式上先取∧，再取指数，下面具体说：

**三维旋转：**李群就是三维旋转矩阵，李代数是三维轴角（长度代表旋转大小，方向代表旋转轴方向），从李群到李代数是分别求轴角的角θ(通过矩阵的迹求反余弦)和向量a（旋转矩阵特征值1对应的特征向量），从李代数到李群就是罗德罗杰斯公式。

**三维变换：**李群是四元变换矩阵，李代数是六维向量，从李群到李代数同样先求角和向量，然后需要求t，从李代数到李群的话通过上面的公式计算。

**32. 求导**

![img](https://pic2.zhimg.com/80/v2-2e29d1527f2439378c04dca51366a495_720w.png)

![img](https://pic2.zhimg.com/80/v2-988dfa2119d304859328b7f429b5e879_720w.jpg)

**33. Mat是如何访问元素的？先访问行还是先访问列？**

Mat访问像素一共有三种方法：使用at()方法、使用ptr()方法、使用迭代器、使用data指针

**（1）使用at()方法：**at()方法又是一个模板方法，所以在使用的时候需要传入图像像素的类型，例如：

![img](https://pic2.zhimg.com/80/v2-97f723922793adf21f4f0ac15fbc2171_720w.png)

**（2）使用ptr()方法：** ptr()方法能够返回指定行的地址（因此正常是先访问行的），然后就可以移动指针访其他的像素。例如

![img](https://pic3.zhimg.com/80/v2-5ebe02cbe02acabe97a3188860ea7b66_720w.png)

这里需要注意的是，有时候在内存中会为了对齐而对末尾的像素有填充，而有时候没有填充。可以使用isContinue()来访问图像是否有填充，对于没有填充的图像，即连续的图像来说，遍历的时候就可以只要一层循环就可以了，他会自己换行将图像变成一维的来处理。

**（3）使用迭代器：**对Mat类型来说，他的迭代器类型可以使用MatIterator_或者Mat_::Iterator类型，具体使用如下

![img](https://pic3.zhimg.com/80/v2-190758f4d2a0d265e3f140b8fb42e57a_720w.png)

用这两个迭代器便可以指定Mat对象的迭代器，注意需要传入模板参数。对迭代器的初始化与C++中的STL一致。

![img](https://pic2.zhimg.com/80/v2-108e88d2a8af9bb04bfac1cc198bd7cd_720w.png)

遍历也和前面指针一样，从图像左上角第一个像素开始遍历三个字节，然后第二个字节，依次遍历，到第一行遍历完后，就会到第二行来遍历。

**（4）使用data指针：**用Mat存储一幅图像时，若图像在内存中是连续存储的（Mat对象的isContinuous == true），则可以将图像的数据看成是一个一维数组，而data（uchar*）成员就是指向图像数据的第一个字节的，因此可以用data指针访问图像的数据，从而加速Mat图像的访问速度。

一般经过裁剪的Mat图像，都不再连续了，如cv::Mat crop_img = src(rect);crop_img 是不连续的Mat图像，如果想转为连续的，最简单的方法，就是将不连续的crop_img 重新clone()一份给新的Mat就是连续的了，例如

![img](https://pic2.zhimg.com/80/v2-d5a4815b8ca418be99cf610bfed33fd9_720w.png)

**34. 写出单目相机的投影模型，畸变模型。**

投影模型一般应该都知道写，但是畸变模型就不一定了…参考《视觉SLAM十四讲》

**投影模型**如下：

![img](https://pic2.zhimg.com/80/v2-bfccd70399680a3e6aa27b8011c38581_720w.jpg)

注意啊，这里空间点是非齐次坐标，而像素变成了齐次坐标，如果空间点也是齐次坐标的话，需要讲变换矩阵写成3×4

的矩阵，最后一列全为0;。

**畸变模型**如下：

畸变模型分为**径向畸变**和**切向畸变**，径向畸变如下：

![img](https://pic1.zhimg.com/80/v2-81b3792d324c18b388aae014d84229c8_720w.jpg)

切向畸变如下：

![img](https://pic4.zhimg.com/80/v2-f1152dbae348bc4d7d794f09ad6cf0df_720w.jpg)

组合上面两式，通过**五个畸变系数**找到空间点在像素平面上的正确位置：

1.将三维空间点P(X,Y,Z)投影到归一化图像平面。设它的归一化坐标为

![img](https://pic1.zhimg.com/80/v2-1a89f14b2bec2f43d3f2781ef97e0858_720w.png)

。

2.对归一化平面上的点进行径向畸变和切向畸变纠正

![img](https://pic2.zhimg.com/80/v2-a57095248974d66509deef53b103608d_720w.png)

3.将纠正后的点通过内参数矩阵投影到像素平面，得到该点在图像上的正确位置

![img](https://pic1.zhimg.com/80/v2-d0a7e2090bb475f3d5e22dd3e6b2b85c_720w.jpg)

值得一提的是，存在两种去畸变处理（Undistort，或称畸变校正）做法。我们可以选择先对整张图像进行去畸变，得到去畸变后的图像，然后讨论此图像上的点的空间位置。或者，我们也可以先考虑图像中的某个点，然后按照去畸变方程，讨论它去畸变后的空间位置。二者都是可行的，不过前者在视觉 SLAM 中似乎更加常见一些。

**35. 安装2D lidar的平台匀速旋转的时候，去激光数据畸变，写代码**

激光雷达里面提到的畸变一般指运动畸变，如果激光数据帧率较同时机器人在运动时就会出现如下图所示情况：

![img](https://pic2.zhimg.com/80/v2-645f5d413435d89f348320a4c631ca79_720w.jpg)

参考激光slam理论与实践（三）：传感器数据处理之激光雷达运动畸变去除

有两种方法：**纯估计方法**和**里程计辅助方法**，其中:

纯估计方法：未知对应点的求解方法，采用极大似然估计方法，而已知对应点的话采用ICP，流程如下：

（1）寻找对应点；

（2）根据对应点，计算R与T；

（3）对点云进行转换，计算误差；

（4）不断迭代，直到误差小于某一值。

里程计辅助方法：用CPU读取激光雷达数据，同时单片机上传里程计数据，两者进行时间同步，在CPU上统一进行运动畸变去除，流程如下：

（1）已知当前激光帧的起始时间

![img](https://pic2.zhimg.com/80/v2-1721fcf227e4c09e0a77efca3b32a071_720w.png)

，

![img](https://pic4.zhimg.com/80/v2-88314de48b64fd21f99c0dd82a39e4af_720w.png)

（2）两个激光束间的时间间隔∗t

（3）里程计数据按照时间顺序存储在一个队列里。

（4）求解当前帧激光数据中的每一个激光点对应的里程计数据（即机器人位姿）

（5）根据求解的位姿把所有的激光点转换到同一坐标系下

（6）重新封装成一帧激光数据发布出去

**36. 给两组已经匹配好的3D点，计算相对位姿变换，写代码**

匹配两组已知坐标的3D点当然是采用ICP，参考《视觉SLAM十四讲》，ICP的解法一共有两种：**SVD方法**和**非线性优化方法**，下面过一遍SVD方法的推导过程：

![img](https://pic1.zhimg.com/80/v2-b862e115cc1344b4be42f2ffccf46f28_720w.jpg)

构建最小二乘的代价函数，求得使误差平方和达到最小的R,t

![img](https://pic1.zhimg.com/80/v2-123585b88e51f61965a31e4fade712f8_720w.jpg)

定义两组点的质心

![img](https://pic1.zhimg.com/80/v2-d62958651478a7f599b35517248cb1f0_720w.jpg)

对代价函数做如下处理：

![img](https://pic1.zhimg.com/80/v2-4305e812c3e8013ebf71a03fa973de08_720w.jpg)

上面三项中最后一项求和为零，因此代价函数变为

![img](https://pic2.zhimg.com/80/v2-d44e792aa3fffe39a8b8902a1069e941_720w.png)

第一项只和R有关，因此我们可以先求得一个R使得第一项最小然后再求t，我们记去质心的点分别为

![img](https://pic3.zhimg.com/80/v2-8f57f4532d5164f04320e009550dcd22_720w.png)

和

![img](https://pic4.zhimg.com/80/v2-c67e43984751cdb7b8f318470171af07_720w.png)

，我们对第一项展开得：

![img](https://pic3.zhimg.com/80/v2-240c760d5cd7f9b6f69ec84233634d0a_720w.png)

第一项和第二项都与R无关，因此最后优化目标函数变为：

![img](https://pic4.zhimg.com/80/v2-f7ed8736ee1fda753c627154914e8227_720w.png)

最后通过SVD方法求得使得上述代价函数最小的R，先定义矩阵：

![img](https://pic3.zhimg.com/80/v2-55333579050ad16e39a53b9038d5a38a_720w.png)

对其进行SVDF分解

![img](https://pic3.zhimg.com/80/v2-fd42b829213bacb4a7fb81f1c57e42be_720w.png)

当W满秩时，R为：

![img](https://pic2.zhimg.com/80/v2-7c4987090cd203e760628e82ba6007e5_720w.png)

解得R后就可以进一步求得t。代码如下：

![img](https://pic3.zhimg.com/80/v2-02967e58fd210849c259e75157ec1f4a_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-1178d99470cc122bb712fc9b3577b537_720w.jpg)

**37. ORB-SLAM初始化的时候为什么要同时计算H矩阵和F矩阵？**

简单地说，因为初始化的时候如果出现纯旋转或者所有特征点在同一个平面上的情况，F矩阵会发生自由度退化，而这个时候H矩阵会有较小误差，因此要同时计算H矩阵和F矩阵，那么这里补充两个问题：

**（1）ORB SLAM是怎样选用哪个矩阵去恢复旋转和平移的呢？**

这部分代码是这个样子的：

![img](https://pic3.zhimg.com/80/v2-bc7b670a7ea9af5c8854797094b87052_720w.jpg)

计算SF和SH的公式如下：

![img](https://pic1.zhimg.com/80/v2-7d0a97d059286c27e069a7184615992c_720w.png)

其中：

![img](https://pic2.zhimg.com/80/v2-5de795aba5873a116e0a52f1774e1ab5_720w.jpg)

然后SH和SF的比值公式如果结果大于0.4的话就选择H矩阵，如果小于0.4的话就选择F矩阵来进行初始化。

**（2）F矩阵退化会发生在哪些情况下？**

F矩阵会在两种条件下发生退化，准确地说是三种，第一种是发生在仅旋转的情况下，第二种是发生在所有空间点共面的情况下，第三种是所有空间点和两个摄像机中心在一个二次曲面上，有可能发生退化（第三种情况暂时不予讨论，可参看《多视图几何》一书），下面我们来看下他们为什么会退化：

**第一种情况：**仅发生旋转，这个比较好理解，基础矩阵满足

![img](https://pic3.zhimg.com/80/v2-3b54c4ba68f23668817129cbe0ebc6fe_720w.png)

在这种情况下，t是零向量，此时求得的基础矩阵是零矩阵，因此无法通过下面的公式求得基础矩阵

![img](https://pic2.zhimg.com/80/v2-4d31f063ddec2c8054edb121b5763a9d_720w.png)

**第二种情况：**所有空间点在一个平面上，这种情况下，匹配点的点集

![img](https://pic1.zhimg.com/80/v2-d277d521d4f3304dd97f01c2b312c68c_720w.png)

满足射影棉变换，即

![img](https://pic3.zhimg.com/80/v2-9e319708608b8d81c92887c87596b3c6_720w.png)

，这时基础矩阵的方程变为

![img](https://pic3.zhimg.com/80/v2-19f8496cf03a0e51387b81f7ba04c4d2_720w.png)

注意这时只要

![img](https://pic4.zhimg.com/80/v2-ea6593069faad386fbb54c6f3358564f_720w.png)

是一个任意的反对称矩阵都满足这个方程，因此F矩阵可以写成

![img](https://pic3.zhimg.com/80/v2-8c712aac3ebeb2e2d76ca8b886289f32_720w.png)

S为任意的反对称矩阵，因此这种情况下只能求出来的F矩阵是一个三参数簇，而不是一个具体的解。

这里再补充一点，我们还要区分好退化和简化的区别，什么情况下会发生F矩阵的简化呢？

**第一种情况：**纯平移运动（就是沿着相机坐标系的z轴运动），这种情况下F矩阵简化成了一个反对称矩阵，并且只有两个自由度（反对称矩阵并且尺度不变性），因此两组匹配点就可以求解这种情况，因此这种情况下，上面**退化的第二种情况就不会发生了，**因为两组匹配点构成的两个空间点肯定都是公面的。

**第二种情况：**纯平面运动（就是沿着相机坐标系的x轴运动），这种情况下F矩阵的对称部分秩为2（具体为什么可能需要查资料推导了），所以会在原本的F矩阵上再添加一个约束，使得自由度变成六个自由度。

第三种情况：标定之后的情形，其实就是F矩阵在把内参获得之后就变成了E矩阵,自由度变成五个自由度，这个没什么好说的。

**38. 说一下Dog-Leg算法**

参考非线性最小二乘法之Gauss Newton、L-M、Dog-Leg

Dog-Leg算法是一种高斯牛顿法和最速下降法混合使用的方法，LM法也是这样一种方法，这两者不同的是，LM法采用的是使用一个阻尼项λ来控制下降的速度在一个合理的半径内，如果λ较小的话说明二阶近似较好，方法更加接近于高斯牛顿法，如果λ较大的话说明二阶近似较差，方法更加接近毓最速下降法

Dog-Leg算法是怎么做的呢？在这之前我们要先回顾下最速下降法和高斯牛顿法中：

**最速下降法：**在《视觉SLAM十四讲》中也提到，最速下降法的增量方向是

![img](https://pic4.zhimg.com/80/v2-30e3f8c01d75df39f447122d989cc29f_720w.png)

![img](https://pic4.zhimg.com/80/v2-3fdd883c58c55c7cf324564b2586eb37_720w.png)

，沿着反向梯度方向前进一个补偿λ即可进行梯度下降，那么λ取多少合适呢？十四讲中并没有说，Dog-Leg算法中给出了评判标准：

假设

![img](https://pic4.zhimg.com/80/v2-b9020dd84d42f6286c1a3d903edcceeb_720w.png)

：

![img](https://pic1.zhimg.com/80/v2-a6a32a8c03a8ac54cfc38e66bacdb830_720w.jpg)

其中

![img](https://pic1.zhimg.com/80/v2-1fcede6509f3f56a5cd85671939a5e64_720w.png)

是最速下降法下降方向，使得上式最小，对α 求导得

![img](https://pic1.zhimg.com/80/v2-3380016110d8b7d49b04fe4942ba354c_720w.jpg)

因此对于最速下降法有

![img](https://pic3.zhimg.com/80/v2-f915434d428707b358b67abe410ddad6_720w.png)

**高斯牛顿法：**这种方法当中是可以同时求得下降方向和下降大小的

![img](https://pic4.zhimg.com/80/v2-121928a0fe514d7552a051c2e02345c3_720w.png)

然后接着介绍**信赖域**，所谓信赖域就是将下降范围控制在这个区域内，在这个范围内二阶泰勒展开能有较好的近似，也即是说不管我们是选择高斯牛顿法还是最速下降法都需要满足

![img](https://pic2.zhimg.com/80/v2-f270dbded0872b49f3bd60d8a200e8ed_720w.png)

,二阶近似才能较好成立，因此Dog-Leg法给出了如下准则：

![img](https://pic2.zhimg.com/80/v2-91f892f10fb629a22d5687a8e1012dc9_720w.jpg)

其中

![img](https://pic2.zhimg.com/80/v2-b250309d8d00cadb34063d0adbd83459_720w.png)

为，上式中第一种情况迭代后下降的点为B点（因为是从另一个博客扒的图，所以里面符号不一样，其中pB指的是高斯牛顿的下降方向，pU指的是最速下降法下降方向）

![img](https://pic3.zhimg.com/80/v2-0846fa48fec98e6d94978898a8244bd6_720w.jpg)

**第二种情况**为迭代后下降的点为**黄色星星点**

![img](https://pic4.zhimg.com/80/v2-aecbab58e35c2eb9f9e9998703488e2f_720w.jpg)

**第二种情况**为迭代后下降的点为**黄色星星点**

![img](https://pic3.zhimg.com/80/v2-85d4e9ff2a057364b1c19503aa838a3e_720w.jpg)

由此可见通过上式成功地将下降区域控制在了信赖区域内，那么信赖区域的半径Δ是怎么更新的呢？如下：

![img](https://pic1.zhimg.com/80/v2-013eeac822bacbd186a6aecbdbdad984_720w.jpg)

其中

![img](https://pic1.zhimg.com/80/v2-df1ecb7ab97b28cef90b595a7de934c0_720w.jpg)

综上所述，Dog-Leg的步骤如下：

step1：初始化

![img](https://pic4.zhimg.com/80/v2-5e2562056e01efa88649a35d792a26c3_720w.png)

step2：求解梯度

![img](https://pic1.zhimg.com/80/v2-d8b30d5ab0e6663a1bc49bd120284828_720w.png)

，如果

![img](https://pic1.zhimg.com/80/v2-50893fa173974fb8ffad1db02144b008_720w.png)

，则退出，否则继续。如果

![img](https://pic1.zhimg.com/80/v2-914b2b5cbdb342c8b2d66cb3a0dee3ac_720w.png)

，则退出，否则继续。

step3：如果半径

![img](https://pic3.zhimg.com/80/v2-016abecf628c7985597b5b226342c322_720w.png)

，则退出迭代；否则继续；

step4：分别根据GaussNewton法和最快下降法计算

![img](https://pic3.zhimg.com/80/v2-e093ea1a9be34b04832c5fd23de7c89e_720w.png)

和

![img](https://pic4.zhimg.com/80/v2-38c00a10bbab65c857cb148e34559787_720w.png)

，然后计算最快下降法的迭代步长

![img](https://pic2.zhimg.com/80/v2-1cd53a2ea1a99e10e6fbc4520ae0a53d_720w.png)

。

step5：根据

![img](https://pic3.zhimg.com/80/v2-e093ea1a9be34b04832c5fd23de7c89e_720w.png)

，

![img](https://pic4.zhimg.com/80/v2-38c00a10bbab65c857cb148e34559787_720w.png)

和信赖区域半径

![img](https://pic3.zhimg.com/80/v2-de63b835e714532001cbd55d8dc55aca_720w.png)

，来计算Dog-Leg步进值

![img](https://pic3.zhimg.com/80/v2-063ff9f130bd83ab73779927d21ded1a_720w.png)

。若

![img](https://pic2.zhimg.com/80/v2-1b6f58017b4124fbf5a000860bd20159_720w.png)

![img](https://pic3.zhimg.com/80/v2-eaf6edc72e6f74cdf34b108e26d7e39e_720w.png)

，则退出迭代；否则继续。

step6：

![img](https://pic3.zhimg.com/80/v2-48bc294dedd391e8f03b823948355afa_720w.png)

，计算增益比

![img](https://pic2.zhimg.com/80/v2-5ec81849f3631d188358c5bdcb626e65_720w.png)

![img](https://pic1.zhimg.com/80/v2-5c731eda90539783727fa88da57bf60c_720w.jpg)

重复step2。

对于ϵ1,ϵ2,ϵ3可以选取任意小的值如

![img](https://pic2.zhimg.com/80/v2-c4c985590c4525b23a9790341263ade9_720w.png)

，只是作为迭代的终止条件，其值得选取对最终的收敛结果影响不大。

对比可以进一步发现LM法是通过阻尼器λ控制下降范围的，λ的不同会导致LM法跟接近于高斯牛顿法还是更接近于最速下降法，而Dog-Leg是先计算高斯牛顿法和最速下降法的结果，然后根据两者结果以及信赖区域半径来确定最后迭代采用那个结果。

**39. Vins-Mono里面什么是边缘化？First Estimate Jacobian？一致性？可观性？**

边缘化其实简单说就是将滑窗中丢弃的图像帧的信息保留下来传递给剩余变量的方式

First Estimate Jacobian是为了解决新测量信息和旧的先验信息构建新的系统时，对某一优化变量求雅克比的线性化点不同导致信息矩阵的零空间发生变化，不可观的变量变成可观变量的问题，做法就是保证变脸的线性化点不变。

一致性应该指的就是线性化点的一致不变，而可观性的定义和现代控制理论中能观性定义是一致的，即通过测量获得状态变量的信息，即该变量是能观的这里给出在深蓝学院的课程中给定一种定义：

对于测量系统 z=h(θ)+ε, 其中

![img](https://pic4.zhimg.com/80/v2-1fb48254d174e60c7ebc293110a25ac3_720w.png)

为测量值， θ∈Rd为系统状态量,ε为测量噪声向量。h(·)是个非线性函数，将状态量映射成测量。对于理想数据，如果以下条件成立，则系统状态量θ可观：

![img](https://pic4.zhimg.com/80/v2-39be636f1e08d727bcb1001625f3144f_720w.png)

**40. 说一下VINS-Mono的优缺点**

VINS-Mono缺点网上总结得好像不是很多，我根据我的经验总结下面几个缺点：

（1）VINS-Mono的前段是采用的提取关键点然后采用光流法追踪，因此对于弱纹理，关键点少的环境鲁棒性和精度差；

（2）同样还是因为前段的问题，因为没有提取特征描述子，而是使用光流法进行的追踪匹配，一旦画面模糊或者图像丢失，相机就会丢，而且没有重定位模块；

（3）在恒速运动下，会使得IMU有一个自由度不客观，因此会发生漂移。

**41. 推导一下VINS-Mono里面的预积分公式**

参考博客VINS-Mono关键知识点总结——预积分和后端优化IMU部分

**42. 在给定一些有噪声的GPS信号的时候如何去精准的定位？**

**43. 如何标定IMU与相机之间的外参数？**

目前我还没有实际标定过，标定方法可以参考贺博的博客Kalibr 标定双目内外参数以及 IMU 外参数，像Intel出的D435i是已经标定号外参数的，另外在VINS-mono中可以对相机的外参数进行估计。

**44. 给你xx误差的GPS，给你xx误差的惯导你怎么得到一个cm级别的地图?**

**45. 计算H矩阵和F矩阵的时候有什么技巧呢？**

其中我能想到的技巧有两点，第一个是RANSAC操作，第二个是归一化操作，RANSAC操作前面已经解释过了，这里主要来分析下归一化操作，在《多视图几何》中提到了一种归一化八点法，方法是先用归一化矩阵对图像坐标进行平移和尺度缩放，然后利用八点法求解单应或者基础矩阵，最后再利用归一化矩阵恢复真实的单应或者基础矩阵，归一化具体操作和优势如下：

**具体操作：**又称各项同性缩放（非同性缩放有额外开销，但是效果并未提升），步骤如下

（1）对每幅图像中的坐标进行平移（每幅图像的平移不同）使点集的形心移至原点

（2）对坐标系进行缩放使得点x=(x,y,w)中的x,y,w总体上有一样的平均值，注意，对坐标方向，选择的是各向同性，也就是说一个点的x和y坐标等量缩放

（3）选择缩放因子使得点x到原点的平均距离等于

![img](https://pic2.zhimg.com/80/v2-ef194261ed9bb9eb714b3f46723b6d75_720w.png)

**优势：**

（1）提高了结果的精度；

（2）归一化步骤通过为测量数据选择有效的标准坐标系，预先消除了坐标变换的影响，使得八点法对于相似变换不变。

**46. 给一组点云，从中提取平面。**

应该有很多方法的，慢慢补充：

**（1）区域生长法：**首先依据点的曲率值对点进行排序，之所以排序是因为，区域生长算法是从曲率最小的点开始生长的，这个点就是初始种子点，初始种子点所在的区域即为最平滑的区域，从最平滑的区域开始生长可减少分割片段的总数，提高效率，设置一空的种子点序列和空的聚类区域，选好初始种子后，将其加入到种子点序列中，并搜索邻域点，对每一个邻域点，比较邻域点的法线与当前种子点的法线之间的夹角，小于平滑阀值的将当前点加入到当前区域，然后检测每一个邻域点的曲率值，小于曲率阀值的加入到种子点序列中，删除当前的种子点，循环执行以上步骤，直到种子序列为空

**（2）随机抽样一致算法**

**（3）基于凸包的凹点挖掘算法：**

1.提取点云的凸包

2.计算凸包每条边的顶点的点密度（即该点 K 个临近点到该点的距离平均值）

3.如果顶点点密度大于所在边的长度的 X 倍，则删除该边，并从内部点中选择出一个满足夹角最大的点，插入边界边，形成两条新的边界边

4.迭代 2 和 3，一直到全部边界边的 X 倍小于其端点的点密度，算法结束

**（4）基于 Delaunay 三角网的轮廓提取算法：**

**A**. 不使用辅助点：

1.首先对点云进行 Delaunay 三角构网

2.同上，判断每条网格边长度的X倍和其端点的点密度之间的大小关系，并删除长的网格边

3.提取只属于一个三角形的边界，作为边界边

4.分类排序，得到有顺序关系的内外轮廓

**B**. 使用辅助点：

1.手动在点云的边界附近选点

2.Delaunay构网

3.判断每个三角形，如果其中一个点是辅助点，而另外两个点是点云中的点，则连接这两个点做为边界边

4.分类排序，得到有顺序关系的内外轮廓

参考提取平面点云的轮廓

**47. 给一张图片，知道相机与地面之间的相对关系，计算出图的俯视图。**

参考如何计算一张图片的俯视图？

简单地说利用射影变换，将原本不垂直的线垂直化（用多视图几何上的话说就是消除透视失真），如下图所示



![img](https://pic2.zhimg.com/80/v2-058993c0de35e017dc0adac9d4f00105_720w.jpg)

**理论推导**如下：

从世界坐标系到图像坐标系的变换如下：

![img](https://pic1.zhimg.com/80/v2-cf8bd0bd22189a9936d3bc5acecabed0_720w.jpg)

上面的透视变换（射影变换）是将一个平面上的点投影到另外一个平面上去，因此上面的空间点[x0,y0,z0,1] 也在同一平面上，我们不妨设第三维坐标为0，有：

![img](https://pic1.zhimg.com/80/v2-4a7083a94637bb05f2e63f9fa506da54_720w.jpg)

上式可以简化为

![img](https://pic4.zhimg.com/80/v2-798e12de5c6c7eee8200d8e8750bebbb_720w.jpg)

这就变化了求解一个单应矩阵，采用四对点就可以进行求解。

因此针对上面那个例子我们的实际操作步骤如下：

（1）灰度化处理

（2）滤波处理

（3）边缘检测

（4）寻找四个点——霍夫变换直线识别

（5）计算 H 矩阵

（6）消除透视失真

**48. 双线性插值如何去做，写公式。**

有同学肯定会好奇为嘛会有这个题，这个问题是承接上一个问题来的，在进行透视变换时会遇到的一个实际问题如下图所示

![img](https://pic2.zhimg.com/80/v2-309e1eff1f780243bdb2978ea027aa49_720w.jpg)

右图（原始图像）中的p点像素(x0,y0)为整数，而到左图中)（变换后的图像）中的p′点像素(x′0,y′0)就不一定是整数，这如何操作呢？一般就是用双线性插值去做。

我们可以发线，p′会落在(x1,y1),(x1+1,y1),(x1+1,y1+1),(x1,y1+1)这四个相邻点的中间，因此我们就要利用(x1,y1),(x1+1,y1),(x1+1,y1+1),(x1,y1+1)，(x1,y1+1),的像素值来计算(x′0,y′0)这点的像素值

![img](https://pic4.zhimg.com/80/v2-8af3d94cf6e5c019c6f536e69cd21b43_720w.jpg)

其实很好记忆的，看下面这张图

![img](https://pic3.zhimg.com/80/v2-76064964997b5cf17083c7ac43848f72_720w.jpg)

写公式的话记住(x1+1,y1+1)前面的系数是ab abab

**49. RGB-D的SLAM和RGB的SLAM有什么区别？**

网上讨论这个的实在太多，我个人觉得单目比较困难点的就是初始化（纯旋转不行，对着平面不行）和尺度问题（需要用Sim解决回环），RGBD-SLAM的话因为有深度因此尺度问题解决了，再环境重建方面会有天然的优势…答得不全，可以再作补充

**50. 什么是ORB特征? ORB特征的旋转不变性是如何做的? BRIEF算子是怎么提取的?**

ORB特征指的是Oriented FAST and rotated BREIF，包括改进后的FAST角点和BREIF特征子，ORB特征的旋转不变形主要是通过计算半径r范围内像素点的一阶矩，连接质心到特征点的向量作为主方向来对周围像素进行旋转，然后提取BRIEF特征子，BRIEF特征描述子通过计算出来的一个二进制串特征描述符来进行提取的。

**51. ORB-SLAM中的特征是如何提取的？如何均匀化的？**

**ORB描述子的提取流程：**

**1.输入图像，并对输入图像进行预处理，将其转换成灰度图像；**

**2.初始化参数，**包括特征点数量nfeatures，尺度scaleFactor，金字塔层数nlevel，初始阈值iniThFAST，最小阈值minThFAST等参数；

**3.计算金字塔图像，**使用8层金字塔，尺度因子为1.2，则通过对原图像进行不同层次的resize，可以获得8层金字塔的图像；

**4.计算特征点：**

（1）将图像分割成网格，每个网格大小为WW=3030像素；

（2）遍历每个网格；

（3）对每个网格提取FAST关键点，先用初始阈值iniThFAST提取，若提取不到关键点，则改用最小阈值minThFAST提取。（注意，初始阈值一般比最小阈值大）

**5.对所有提取到的关键点利用八叉树的形式进行划分：**

（1）按照像素宽和像素高的比值作为初始的节点数量，并将关键点坐标落在对应节点内的关键点分配入节点中；

（2）根据每个节点中存在的特征点数量作为判断依据，如果当前节点只有1个关键点，则停止分割。否则继续等分成4份；

（3）按照上述方法不断划分下去，如图所示，可见出现一个八叉树的结构，终止条件是节点的数目Lnode大于等于要求的特征点数量nfeatures；

（4）对满足条件的节点进行遍历，在每个节点中保存响应值最大的关键点，保证特征点的高性能；

![img](https://pic4.zhimg.com/80/v2-6b5a0548447d7fbb91c2c1c3f015e713_720w.jpg)

**6.对上述所保存的所有节点中的特征点计算主方向，**利用灰度质心的方法计算主方向，上一讲中我们已经讲解过方法，这讲就不再赘述了；

**7.对图像中每个关键点计算其描述子，**值得注意的是，为了将主方向融入BRIEF中，在计算描述子时，ORB将pattern进行旋转，使得其具备旋转不变性；参考ORBSLAM2中ORB特征提取的特点



> source：[2022最新SLAM面试题汇总（持续更新中）](https://zhuanlan.zhihu.com/p/544043873)

目前机器人SLAM问题是一个非常值得研究的方向，在未知环境中，首先要通过SLAM技术获得环境的地图，然后才能进行导航。这个方向是近几年比较新的研究方向，相关的机器人公司以及研究机器人的大厂也很需要SLAM方向的人才，比如大疆、美团、旷视科技等已经在这个行业有了一定的产品应用。在SLAM方向的面试中，总结的面试题如下：

1.重定位和回环检测的区别是什么？

2.单应矩阵H和基础矩阵F的区别是什么？

3.视觉SLAM方法的分类和对应的特点分析。

4.关键帧的作用是什么？

5.如何选择关键帧？

6.相机传感器的分类及其优缺点是什么？

7.ROS中rosrun和roslaunch的区别是什么？

8.请描述视觉SLAM的框架以及各个模块的作用是什么？

9.SLAM中的绑架问题是什么？

10.在视觉SLAM中可能用到有关的边缘检测算子有哪些？

11.在SLAM中，如何对匹配好的点做进一步的处理，更好保证匹配效果？

12.SLAM后端有滤波方法和非线性优化方法，这两种方法的优缺点是什么？

13.什么是BA优化？

14.描述一下RANSAC算法。

15.相似变换、仿射变换、射影变换的区别是什么？

16.ICP算法的原理是什么？简要叙述一下。

17.四元数的相关概念是什么，请解释一下。

18.激光SLAM中的具体方法有什么？请解释一下每种方法的特点。

19.说明UKF，EKF和PF之间的关系。

20.点云配准算法目前有哪些？

建议大家先自己答题，再对照参考答案噢~

\----------------------------------------------------------------

**参考答案**

**1.重定位和回环检测的区别是什么？**

重定位是跟丢以后重新找回当前的姿态，通过当前帧和关键帧之间的特征匹配，定位当前帧的相机位姿。重定位就是重新定位，当前图像因为和最近的图像或者局部地图之间缺乏足够的匹配，导致机器人无法确定自己的位姿，此时处于当前状态的机器人不再知道其在地图中的位置，也叫做机器人被“绑架”，就说的是人质被蒙上双眼带到未知地方，蒙罩去掉后完全不知道自己在哪里，这时候就需要充分利用之前建好的地图或者存好的数据库。此时机器人需要观察周围环境，并且从已有地图中寻找可靠的匹配关系，一般是关键帧信息，这样就可以根据已有信息“重新”估计机器人的姿态。

回环检测是为了解决位置估计随时间漂移的问题。主要是通过识别曾经到过的场景，将其与当前帧对应，优化整个地图信息，包括3D路标点、相机位姿和相对尺度信息。回环的主要目的是降低机器人随时间增加，轨迹中累积的漂移，一般发生在建图过程中。这是因为基于运动传感器或者视觉信息的里程计容易出错，使估计的轨迹偏离其实际真实的情况。通过回环，优化整个地图信息，包括3D路标点、相机位姿和相对尺度信息。回环检测提供了回环帧与所有历史帧的关系，可以极大减少误差。回环主要是纠正机器人/相机轨迹，而重新定位再从未知状态找回姿态。两者都需要当前图像预先访问过之前的位置附近，本质上都是一个图像识别问题。

重定位和回环检测的区别：

重定位主要为了恢复姿态估计，而回环是为了解决漂移，提高全局精度。二者容易混淆的原因是重定位通常也需要找到与之前帧的对应关系求解出姿态，而这可以通过回环来完成，很多算法是可以共享的。

**2.单应矩阵H和基础矩阵F的区别是什么？**

（1）基础矩阵F和单应矩阵H所求相机获取图像状态不同而选择不同的矩阵。

（2）本质矩阵E和基础矩阵F之间相差相机内参K的运算。

（3）只旋转不平移求出F并分解出的R，T和真实差距大不准确，能求H并分解得R。

**3.视觉SLAM方法的分类和对应的特点分析。**

视觉SLAM可以分为特征点法和直接法。特征点法是根据提取、匹配特征点来估计相机运动，优化的是重投影误差，对光照变化不敏感，是比较成熟的方案，常见的开源方法有ORB-SLAM等。

特征点法的优点：

（1）特征点本身对光照、运动、旋转比较不敏感，因此稳定性更好。

（2）相机运动较快，也能跟踪成功，鲁棒性较好。

（3）研究时间较久，方案比较成熟。

特征点法的缺点：

（1）关键点提取、描述子匹配时间长。

（2）特征点丢失的场景无法使用。

（3）只能构建稀疏地图。

直接法根据相机的亮度信息估计相机的运动，可以不需要计算关键点和描述子，优化的是光度误差，根据使用像素可分为稀疏、半稠密、稠密三种，常见的方案是SVO、LSD-SLAM等。

直接法的优点：

（1）速度快，可以省去计算特征点和描述子时间。

（2）可以在特征缺失的场合，特征点法在该情况下会急速变差。

（3）可以构建半稠密乃至稠密地图。

直接法的缺点：

（1）因为假设了灰度不变，所以易受光照变化影响。

（2）要求相机运动较慢或采样频率较高。

（3）单个像素或像素块区分度不强，采用的是数量代替质量的策略。

**4.关键帧的作用是什么？**

关键帧目前是一种非常常用的方法，可以减少待优化的帧数，并且可以代表其附近的帧。

**5. 如何选择关键帧？**

选取关键帧的指标：

（1）距离上一关键帧的帧数是否足够多（时间）。运动很慢的时候，就会选择大量相似的关键帧，冗余、运动快的时候又丢失了很多重要的帧。

（2）距离最近关键帧的距离是否足够远（空间）运动。相邻帧根据姿态计算运动的相对大小，可以是位移，也可以是旋转，或者二者都考虑了。

（3）跟踪质量（主要根据跟踪过程中搜索到的点数和搜索的点数比例）/共视特征点。这种方法记录了当前视角下的特征点数或者视角，当相机离开当前场景时才会新建关键帧，避免了上一种方法存在的问题，缺点是比较复杂。

**6.相机传感器的分类及其优缺点是什么？**

视觉SLAM常用的相机包括单目相机、双目相机和深度相机。

单目相机的优点：

（1）应用最广，成本可以做到非常低。

（2）体积小，标定简单，硬件搭建也简单。

（3）在有适合光照的情况下，可以适用于室内和室外环境。

单目相机的缺点：

（1）具有纯视觉传感器的通病：在光照变化大，纹理特征缺失、快速运动导致模糊的情况下无法使用。

（2）SLAM过程中使用单目相机具有尺度不确定性，需要专门的初始化。

（3）必须通过运动才能估计深度，帧间匹配三角化。

双目相机一般有Indemind、小觅和ZED等。

双目相机的优点：

（1）相比于单目相机，在静止时就可以根据左右相机视差图计算深度。

（2）测量距离可以根据基线调节。基线距离越大，测量距离越远。

（3）在有适合光照的情况下，可以适用于室内和室外。

双目相机的缺点：

（1）双目相机标定相对复杂。

（2）用视差计算深度比较消耗资源。

（3）具有纯视觉传感器的通病：在光照变化较大、纹理特征缺失、快速运动导致模糊的情况下无法使用。

深度相机一般有Kinect系列、Realsense系列、Orbbec和Pico等。

深度相机的优点：

（1）使用物理测距方法测量深度，避免了纯视觉方法的通病，适用于没有光照和快速运动的情况。

（2）相对双目相机，输出帧率较高，更适合运动场景。

（3）输出深度值比较准，结合RGB信息，容易实现手势识别、人体姿态估计等应用。

深度相机的缺点：

（1）测量范围窄，容易受光照影响，通常只能用于室内场景。

（2）在遇到投射材料、反光表面、黑色物体情况下表现不好，造成深度图确实。

（3）通常分辨率无法做到很高，目前主流的分辨率是640×480.

（4）标定比较复杂。

**7.ROS中rosrun和roslaunch的区别是什么？**

rosrun允许在任意软件包中运行可执行文件，而无需先在其中进行cd或roscd。

Roslaunch可以通过ssh在本地和远程轻松启动多个ros节点，以及在参数服务器上设置参数。它包括自动重生已经死掉的进程的选项。roslaunch接收一个或多个XML配置文件，这些文件指定要设置的参数和要启动的节点以及应在其上运行的计算机。

rosrun只能运行一个节点，如果要运行多个节点，就需要多次使用rosrun命令，而roslaunch可以采用xml格式描述运行的节点，同时运行多个节点。

**8.请描述视觉SLAM的框架以及各个模块的作用是什么？**

（1）传感器信息读取。在视觉SLAM中主要是相机图像信息的读取和预处理，在机器人中，还会有码盘、惯性传感器等信息的读取和同步。

（2）视觉里程计就是前端，其任务是估算相邻图像间相机运动，以及局部地图的样子。

（3）后端优化。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对它们进行优化，得到全局一致的轨迹和地图。

（4）回环检测。判断机器人是否到达过去先前的位置，如果检测到回环，它会把信息提供给后端进行检测。

（5）建图。根据估计的轨迹，建立与任务要求对应的地图。

**9.SLAM中的绑架问题是什么？**

绑架问题就是重定位，指的是机器人缺少先前位置信息的情况下确定当前位姿。比如机器人在一个已经构建好地图的环境中，但它并不知道自己在地图中的相对位置，或者在移动过程中，由于传感器的暂时性功能故障或者相机的快速移动，导致先前的位置信息丢失，因此得重新确定机器人的位置。初始化绑架是一个通常状况的初始化问题，可以使用粒子滤波方法，重新分散例子到三维空间，被里程信息和随机扰动不断更新，初始化粒子收敛到可解释观察结果的区域。追踪丢失状态绑架，即在绑架发生之前，系统已经保存当前状态，则可以使用除视觉传感器之外的其他的传感器作为候补测量设备。

**10.在视觉SLAM中可能用到有关的边缘检测算子有哪些？**

在边缘检测一般分为滤波、增强和检测三个步骤，其基本原理是用高斯滤波器进行去噪，之后再用卷积内核寻找像素梯度。边缘检测算子：

（1）canny算子：一种完善的边缘检测算法，抗噪能力强，用高斯滤波平滑图像，用一阶偏导的有限差分计算梯度的幅值和方向，对梯度幅值进行非极大值抑制，采用双阈值检测和连接边缘。

（2）sobel算子：一阶导数算子，引入局部平均运算，对噪声具有平滑作用，抗噪声能力强，计算量较大，但定位精度不高，得到的边缘比较粗，适用于精度要求不高的场合。

（3）laplacian算子：二阶微分算子，具有旋转不变性，容易受噪声影响，不能检测边缘的方向，一般不直接用于检测边缘，而是判断明暗变化。

**11.在SLAM中，如何对匹配好的点做进一步的处理，更好保证匹配效果？**

（1）确定匹配最大距离，汉明距离小于最小距离的两倍。

（2）使用KNN-matching算法，在这里设置K为2，每个匹配得到两个最接近的描述子，然后计算最接近距离和次接近距离之间的比值，当比值大于既定值时，才作为最终匹配。

（3）使用RANSAC算法找到最佳单应性矩阵，该函数使用的特征点同时包含正确和错误匹配点，因此计算的单应性矩阵依赖于二次投影的准确性。

**12.SLAM后端有滤波方法和非线性优化方法，这两种方法的优缺点是什么？**

滤波方法的优点：在当前计算资源受限、待估计量比较简单的情况下，EKF为代表的滤波方法非常有效，经常用在激光SLAM中。

滤波方法的缺点：存储量和状态量是平方增长关系，因为存储的是协方差矩阵，因此不适合大型场景。但是现在视觉SLAM的方案中特征点的数据很大，滤波方法效率是很低的。

非线性优化方法一般以图优化为代表，在图优化中BA是核心，而包含大量特征点和相机位姿的BA计算量很大，无法实时。在后续的研究中，人们研究了SBA和硬件加速等先进方法，实现了实时的基于图优化的视觉SLAM方法。

**13.什么是BA优化？**

BA的全称是Bundle Adjustment优化，指的是从视觉重建中提炼出最优的三维模型和相机参数，包括内参和外参。从特征点反射出来的几束光线，在调整相机姿态和特征点空间位置后，最后收束到相机光心的过程。BA优化和冲投影的区别在于，对多段相机的位姿和位姿下的路标点的空间坐标进行优化。

将误差表示为：

![img](https://pic2.zhimg.com/80/v2-294cb9ef5ade23aa9ea3b67fc0496c21_720w.jpg)

也就是：

![img](https://pic2.zhimg.com/80/v2-d4c9094d2e278460be9047c89c0f13ed_720w.jpg)

可以计算出误差对位姿和路标坐标的偏导：

![img](https://pic1.zhimg.com/80/v2-e808b1ba49069c2b422e05e6f29cf130_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-855b719a57b7fd914fcb587b516a3b02_720w.jpg)

对于特征点位置p和m个位姿以及n个特征点，表示为：

![img](https://pic4.zhimg.com/80/v2-bdd2a3a4f470be5c565fc02dce33001b_720w.jpg)

上式中的右边简写为：

![img](https://pic4.zhimg.com/80/v2-9d6b95f3bd263d192cd111b644ca002b_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-202c8a00d820221fa425d66704a51a79_720w.jpg)

然后，将优化的目标函数表示为：

![img](https://pic4.zhimg.com/80/v2-a6edd7b11e6a1085058e972ec6b3aca7_720w.jpg)

目标函数也可以表示为：

![img](https://pic2.zhimg.com/80/v2-d73b6ec9a9c4469ff0462cef05ce78d9_720w.jpg)

对于线性增量方程：

![img](https://pic4.zhimg.com/80/v2-72aae0905e8ad18a7fca70c8deda27d7_720w.jpg)

这里的

![img](https://pic1.zhimg.com/80/v2-b739cbad56f8e9959c7d2ff7b4e56cf0_720w.jpg)

将雅克比矩阵分块为：



![img](https://pic4.zhimg.com/80/v2-56adc1eaf1025d3123f0610f075ae1ab_720w.jpg)

则：



![img](https://pic1.zhimg.com/80/v2-223bcba5fb20456cc368ee9c1dc6222c_720w.jpg)

**14.描述一下RANSAC算法。**

RANSAC算法是随机采样一致算法，从一组含有“外点”的数据中正确估计数学模型参数的迭代算法。“外点”一般指的是数据中的噪声，比如匹配中的误匹配和估计曲线中的离群点。因此，RANSAC算法是一种“外点”检测算法，也是一种不确定的算法，只能在一种概率下产生结果，并且这个概率会随着迭代次数的增加而加大。RANSAC主要解决样本中的外点问题，最多可以处理50%的外点情况。

RANSAC主要通过反复选择数据中的一组随机子集来达成目标，被选取的子集假设为局内点，验证步骤如下：

（1）一个模型适用于假设的局内点，也就是说所有的未知参数都能从假设的局内点计算得到。

（2）使用（1）中得到的模型测试所有其他数据，如果某个点适用于估计的模型，认为它也是局内点。

（3）如果有足够多的点被归类为假设的局内点，则估计的模型就足够合理。

（4）使用假设的局内点重新估计模型，因为它仅仅被初始的假设局内点估计。

（5）最终，通过估计局内点和模型的错误率估计模型。

**15.[相似变换、仿射变换、射影变换的区别](https://link.zhihu.com/?target=https%3A//www.freesion.com/article/35571024388/%238.%20%E7%9B%B8%E4%BC%BC%E5%8F%98%E6%8D%A2%E3%80%81%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2%E3%80%81%E5%B0%84%E5%BD%B1%E5%8F%98%E6%8D%A2%E7%9A%84%E5%8C%BA%E5%88%AB)是什么？**

相似变换相当于等距变换和均匀缩放的一个复合，用S表示变换矩阵，S为3×3矩阵，

![img](https://pic4.zhimg.com/80/v2-2d57b2aaf841bf7d801386ee2a13cd17_720w.jpg)

左上角2×2矩阵为旋转部分，tx和ty为平移因子，具有4个自由度，即旋转、x方向平移、y方向平移和缩放因子s。相似变换前后长度比，夹角，虚圆点I，J保持不变。

仿射变换相当于一个平移变换和一个非均匀变换的复合，用A矩阵表示，A为3×3矩阵，

![img](https://pic1.zhimg.com/80/v2-86b173aac1eb04647fba20cb5dc91678_720w.jpg)

其中A可以分解为：

![img](https://pic3.zhimg.com/80/v2-fc3c67eae2c53eda0e3eec9389f7ad4e_720w.jpg)

其中

![img](https://pic4.zhimg.com/80/v2-9e11ab5ac8090a7109aad377f2e4b377_720w.jpg)

左上角2×2矩阵为旋转部分，tx和ty为平移因子，它有6个自由度，即旋转4个，x方向平移，y方向平移。它能保持平移性，不能保持垂直性，图像中各部分变换前后面积比保持不变，共线线段或者平行线段的长度比保持不变，矢量的线性组合不变。

射影变换由有限次中心射影的面积定义的两条直线间的对应变换称为一维射影变换，由有限次中心射影的面积定义的两个平面之间的对应变换称为二维射影变换。射影变换是最一般的线性变换，有8个自由度，保持重合关系和交比不变，但不会保持平行性。

**16.ICP算法的原理是什么？简要叙述一下。**

ICP算法的核心是最小化目标函数：

![img](https://pic2.zhimg.com/80/v2-29462814168893e4d22087fb0b28240d_720w.jpg)

目标函数是指是对所有对应点之间的欧式距离的平方和。

**17.四元数的相关概念是什么，请解释一下。**

四元数在程序中使用很广泛，但在SLAM中四元数的概念比较难理解。四元数是Hamilton找到的一种扩展复数，四元数具有一个实部和三个虚部：

![img](https://pic4.zhimg.com/80/v2-c403ad1afb13ced6f1bdccd66c925ca3_720w.jpg)

其中i,j,k是四元数的三个虚部，满足下式：

![img](https://pic2.zhimg.com/80/v2-6c5c49f6e64f3bc778e51561fe0ae1d9_720w.jpg)

也可以使用标量和向量来表示四元数：

![img](https://pic4.zhimg.com/80/v2-a321fccf8d267bffa04e5b719adee697_720w.jpg)

在上式中，标量s是四元数的实部，向量v是虚部。

四元数可以表示三维空间中任意一个旋转，与旋转矩阵类似，假设某个旋转是围绕单位向量

![img](https://pic1.zhimg.com/80/v2-0bbbb4b83a60df286eac80a6ef927b44_720w.jpg)

进行了角度为θ的旋转，则该旋转的四元数形式为：

![img](https://pic2.zhimg.com/80/v2-d1b8a6b4123b0507d159a3c47012ab69_720w.jpg)

上式实质上是模长为1的四元数，也就是单位四元数。反之，也可以通过任意长度为1的四元数计算对应旋转轴和夹角：

![img](https://pic4.zhimg.com/80/v2-0e45729a6ecea8ce2b126028835e3993_720w.jpg)

如果某个四元数的长度不为1，可以通过归一化转化为模长为1的四元数。

对四元数的θ加上2π，就可以得到相同旋转，但对应的四元数变为-q。因此，在四元数中，任意的旋转都可以由两个互为相反数的四元数表示。如果θ为0的话，则得到一个没有任何旋转的四元数：

![img](https://pic1.zhimg.com/80/v2-d97d68486d2dbcd75d798ba9c04ea61c_720w.jpg)

**18.激光SLAM中的具体方法有什么？请解释一下每种方法的特点。**

激光雷达分为单线和多线两种，单线雷达一般应用在平面运动场景，多线雷达应用在三维运动场景。

（1）单线雷达构建二维地图的SLAM算法称为2D lidar SLAM，包括Gmapping、hector、karto和cartographer算法，在二维平面内运动，扫描平面与运动平面平行。

Gmapping是一种基于粒子滤波的2D激光雷达SLAM，构建二维栅格地图。融合里程计信息，没有回环检测。优点是在小场景中，计算量小，速度较快。 缺点是每个粒子都携带一幅地图，无法应对大场景（内存和计算量巨大）；如果里程不准或标定参数不准，在长回廊等环境中容易把图建歪。

hector SLAM是完全基于s[can](https://link.zhihu.com/?target=http%3A//www.elecfans.com/tags/can/)-matching的，使用迭代优化的方法来求匹配的最佳位置，为避免陷入局部极值，也采用多分辨率的地图匹配。 由于完全依赖于scan matching，要求雷达的[测量](https://link.zhihu.com/?target=http%3A//www.hqchip.com/app/851)精度较高、角度范围大，扫描速度较高（或移动速度慢）。噪声多、边角特征点少的场景就很容易失败。 原文所提出方法的特点还在于，加入IMU，使用EKF估计整体的6DoF位姿，并根据roll, pitch角将激光扫描数据投影到XY平面，因而支持激光雷达有一定程度的倾斜，比如手持或机器人运动在不是很平整的地面上。

karto是基于scan-matching，回环检测和图优化SLAM算法，采用SPA（Spa[rs](https://link.zhihu.com/?target=http%3A//www.elecfans.com/tags/rs/)e Pose [Ad](https://link.zhihu.com/?target=https%3A//dfm.elecfans.com/uploads/software/hqdfm.zip%3Fneilian)justment）进行优化。

cartographer是谷歌开源的激光SLAM框架，主要特点在于： 1.引入submap，scan to submap matching，新到的一帧数据与最近的submap匹配，放到最优位置上。如果不再有新的scan更新到最近的submap，再封存该submap，再去创建新的submap。 2.回环检测和优化。利用submap和当前scan作回环检测，如果当前scan与已经创建的submap在距离上足够近，则进行回环检测。检测到回环之后用ceres进行优化，调整submap之间的相对位姿。为了加快回环检测，采用分枝定界法。

（2）3D lidar SLAM算法是针对多线雷达的SLAM方法，包括LOAM、Lego-LOAM和LOAM-livox等。

LOAM是针对多线激光雷达的SLAM算法，主要特点在于：1) 前端抽取平面点和边缘点，然后利用scan-to-scan的匹配来计算帧间位姿，也就形成了里程计；2) 由估计的帧间运动，对scan中的每一个点进行运动补偿；3) 生成map时，利用里程计的信息作为submap-to-map的初始估计，再在利用submap和map之间的匹配做一次优化。 LOAM提出的年代较早（2014），还没有加入回环优化。

LeGO-LOAM在LOAM的基础上主要改进：1) 地面点分割，点云聚类去噪；2）添加了ICP回环检测和gtsam优化。

LOAM_livox是[大疆](https://link.zhihu.com/?target=http%3A//www.elecfans.com/tags/%E5%A4%A7%E7%96%86/)2019年公布的面向小FOV Lidar的LOAM算法。相比LOAM，做了一些改动。算法的特点： 1.添加策略提取更鲁棒的特征点：a) 忽略视角边缘有畸变的区域; b) 剔除反射强度过大或过小的点 ; c) 剔除射线方向与所在平台夹角过小的点; d) 部分被遮挡的点 2.与LOAM一样，有运动补偿 3.里程计中剔除相对位姿解算后匹配度不高的点（比如运动物体）之后，再优化一次求解相对位姿。

**19.说明UKF，EKF和PF之间的关系。**

从精度的角度来看，所有高精度都是通过增加计算量来换来的，如果UKF通过加权减少Sigma点的方法来降低计算负载，那么精度在一定程度上会低于一阶泰勒展开的EKF线性化。除了EKF和UKF之间的时间复杂性问题外，我们还需要检查它们的理论性能。从以往的一些研究中中，我们知道UKF可以将状态估计和误差协方差预测到4阶精度，而EKF只能预测状态估计的2阶和误差协方差的4阶。但是，只有在状态误差分布中的峰度和高阶矩很明显的情况下，UKF才能进行更准确的估计。在我们的应用中，四元数分量协方差的大小显着小于统一性，这意味着峰度和更高阶矩非常小。这一事实说明了为什么UKF的性能不比EKF好。

另外，采样率也是另外一个拉小UKF与EKF差距的因素，对许多动态模型（有论文提到四元数动态）随着采样间隔的缩短，模型愈发趋近准线性化，那么越小的步长，积分步长把（四元数）传播到单位球面的偏差就越小。因此最小化了线性化误差。

最后，也是最根本的在选取EKF和UKF最直观的因素，UKF不用进行雅可比矩阵计算，但是，许多模型的求导是极为简单的，在最根本的地方UKF没有提供更优的解决方案。这也使得，状态模型的雅可比计算的简单性允许我们在计算EKF和UKF用相同的方法计算过程误差协方差。

UKF并不是万能的，也不是一定比EKF优秀，很多时候需要根据情况选择特定的滤波。

**20.点云配准算法目前有哪些？**

点云配准算法目前有ICP、KC、RPM、形状描述符配准和UPF/UKF。

（1）ICP

ICP算法简单且计算复杂度度低，使它成为最受欢迎的刚性点云配准方法。ICP算法以最近距离标准为基础迭代地分配对应关系，并且获得关于两个点云的刚性变换最小二乘。然后重新决定对应关系并继续迭代知道到达最小值。目前有很多点云配追算法都是基于ICP的改进或者变形，主要改进了点云选择、配准到最小控制策略算法的各个阶段。ICP算法虽然因为简单而被广泛应用。但是它易于陷入局部最大值。ICP算法严重依赖初始配准位置，它要求两个点云的初始位置必须足够近，并且当存在噪声点、外点时可能导致配准失败。

（2）KC

KC算法应用了稳健统计和测量方法。Tsin和Kanade应用核密度估计，将点云表示成概率密度，提出了核心相关（Kernel Correlation，简称KC）算法。这种计算最优配准的方法通过设置两个点云间的相似度测量来减小它们的距离。对全局目标函数执行最优化算法，使目标函数值减小到收敛域。因为一个点云中的点必须和另一个点云中的所有点进行比较，所以这种方法的算法复杂度很高。

（3）RPM

为了克服ICP算法对初始位置的局限性，基于概率论的方法被研究出来。Gold提出了鲁棒点匹配（Robust Point Matching，简称RPM）算法，以及其改进算法。这种方法应用了退货算法减小穷举搜索时间。RPM算法既可以用于刚性配准，也可以用于非刚性配准。对于RPM算法，在存在噪声点或者某些结构缺失时，配准可能失败。

（4）形状描述符配准

形状描述符配准在初始位置很差的情况下也能大体上很好的实现配准。它配准的前提是假设了一个点云密度，在没有这个特殊假设的情况下，如果将一个系数的点云匹配到一个稠密的点云，这种匹配方法将失败。

（5）UPF/UKF

尽管UPF算法能够精确的配准较小的数据集，但是它需要大量的粒子来实现精确配准。由于存在巨大的计算复杂度，这种方法不能用于大型点云数据的配准。为了解决这个问题，UKF算法被提出来，这种方法收到了状态向量是单峰假设的限制，因此，对于多峰分布的情况，这种方法会配准失败。



> source：[自动驾驶面试题汇总（2022秋招题库）——持续更新](https://www.bilibili.com/read/cv13721554?spm_id_from=333.999.0.0)

一、惯性导航方向

IMU测量方程是什么？噪声模型是什么？

惯导误差模型是怎么来的？比如15维的卡尔曼滤波模型。

GPS双天线安装偏角是怎么标定的？

多传感器之间是怎么对时的？

GPS到来时是有延时的，而IMU给出的加速度和角速度是实时的，这种情况下怎么处理延时？怎么做的融合？

DR递推的原理是什么？大概怎么去做？

组合导航卡尔曼滤波过程噪声是如何调参的？

二、点云算法方向
最近邻问题有哪几种典型解法？

怎么对KdTree进行插入操作？怎么确定一个节点的分类面？

怎么对KdTree进行Search By Range和Search By KNN操作？

举出除了KdTree以外的近邻计算方法（栅格、B树、R树、四叉、八叉树等）。

给定一组点，如何计算其拟合平面？如何计算其拟合直线？解释其方法的意义。

举出常见的点云的registration方法。

说明ICP的详细过程，要求说明代数解法和匹配问题解法。

说明NDT的详细过程，Normal distribution的含义是什么。

匹配问题除了最近邻还有什么解法？说明匈牙利算法、最大流/最小割、谱方法等其中一种。

解释混合高斯模型含义。解释EM算法的原理。

三、状态估计方向
从贝叶斯滤波器角度推出卡尔曼滤波器方程。

从增益最优化角度推出卡尔曼滤波器方程。

从Cholesky方程推出卡尔曼滤波器方程。

解释KF中的噪声矩阵含义。运动方程中估计噪声是变大还是变小？修正方程中估计噪声是变大还是变小？

RTS与KF之间的联系？

将卡尔曼滤波器推广至EKF。

解释数值矩阵求逆的几种做法（QR、Cholesky、SVD）。

什么是Moore-Penrose逆？如何计算Moore-Penrose逆？

SVD是什么？SVD是如何求解的？

特征值是什么？如何计算矩阵的特征值与特征向量？什么样的矩阵必然能对角化？不能对角化的矩阵的标准形式是什么？什么是Jordan标准形？

如何求解线性最小二乘解？如何求解零空间解？说明特征值方法和奇异值方法之间的联系。

描述图优化和最小二乘之间联系。画出VIO中常用的图优化模型。

稀疏图优化的稀疏性体现在哪里？要求答出稀疏Schur和稀疏Cholesky之一。

描述滤波器与最小二乘之间的联系？说明为什么卡尔曼滤波器可以看成两个时刻间的最小二乘。

说明UKF、EKF和PF之间的关系。

解释UKF中的Sigma采样点关系。

解释PF中的重要性重采样的过程是如何做的。解释轮盘赌原理。

解释李群李代数在三维状态估计中的作用。

流形是怎么定义的？流形在局部与R3同胚是什么含义？为什么说SO3是一个流形？

解释SO3, SE3中的Exp和Log的原理。解释BCH的原理和作用。

分别使用左右扰动模型，求解几个常见的雅可比：


22.解释四元数的更新与SO3的更新方式有何异同。

23. 说明四元数运动模型与SO3运动模型之间的联系。

24. 解释高斯推断和概率学中边缘化之间的关系。解释边缘化与卡尔曼滤波器之间的关系。

25. 什么是M估计？说明M估计与核函数之间的关系？

四、计算机视觉/VIO方向
单应矩阵、基础矩阵、本质矩阵的定义？

相机内参和外参的含义？如果将图像放大两倍，内外参如何变化？

径向和切向畸变模型含义，鱼眼模型含义（回答等距投影模型即可）？

极线是什么？对极约束是什么？描述了什么几何关系？

八点法原理与过程。

预积分相比于传统积分的差异在哪里？

预积分的测量模型和噪声模型是什么？预积分对零偏是怎么处理的？为什么要这样处理？

说明预积分的图优化模型。

解释重投影模型和BA的原理。

说明PnP问题的解法。

说明RANSAC原理，讨论存在的问题。

解释单目VIO的初始化过程。需要估计哪些量？重力方向和尺度如何估计？

为什么单目VSLAM会有尺度漂移？如何解释这种尺度漂移？现实当中有没有解决办法？

举出几种光流方法（LK，HS等）。说明LK光流的建模方式。

五.C++方向
C++函数指针有哪几类？函数指针、lambda、仿函数对象分别是什么？

如何利用谓词对给定容器进行自定义排序？

传递引用和传递值的区别？传递常引用和传递引用之间的区别？传递右值引用和传递引用之间的区别？

函数对象应该通过什么传递？

什么是万能引用？用途是什么？

什么是完美转发？用途是什么？

std::unorded_map和std::map之间的差异是什么？

虚函数、虚表的原理

如何在c++中创建线程？如何在线程间同步？

互斥锁是什么？用途是什么？条件变量又是什么？为什么要用条件变量？

智能指针和祼指针之间的差异？为什么要用指针的引用计数？

智能指针分哪几种？std::unique_ptr, std::shared_ptr, std::weak_ptr各有何用途？

悬挂指针会导致什么问题？如何避免？

traits是什么？什么时候用traits？


参考答案（部分）
一、惯性导航方向
1. IMU测量方程是什么？噪声模型是什么？

中值积分的情况下，IMU的测量方程为：


IMU的随机误差一般包括以下几类，各类误差项及其原理如下（以陀螺仪为例）：
（1） 量化噪声
量化噪声是数字传感器必然出现的噪声，我们通过AD采集把连续时间信号采集成离散信号，在这个过程中，精度就会损失，损失的精度大小和AD采样的精度有关（这里具体指的是模数转换时，AD器件的位数，位数越高采样越精确），精度越高，量化噪声越小。
（2） 角度随机游走
陀螺敏感角速率并输出时是有噪声的，这个噪声里面的白噪声成分叫宽带角速率白噪声，我们计算姿态时，本质上是对角速率做积分，这必然会对噪声也做了积分。白噪声的积分并不是白噪声，而是一个马尔可夫过程，即这一次的误差是在上一次误差的基础上累加一个随机白噪声得到的。角度误差所包含的这种马尔可夫性质的误差就叫做角度随机游走。
（3） 角速率随机游走
从理解上和角度随机游走一样，角速率里面并不全是白噪声，它也有马尔可夫性质的误差成分，而这个误差是由宽带角加速率白噪声累积的结果。
（4） 零偏不稳定性噪声
这应该是大家再熟悉不过的一个误差项了，如果一个陀螺只让你用一个指标来体现精度，那必然就是它了。但是这个指标的理解上却不像前几个参数那样直白。
我们可以先把它理解为零偏随时间的缓慢变化，假设在刚开始时零偏大小是某个值，那么过一段时间之后，零偏便发生了变化，具体变化成了多少，无法预估，所以就要给他一个概率区间，来描述它有多大的可能性落在这个区间内，时间越长，区间越大。
实际上，如果你真的测的时间足够长，会发现它也不会无限制增长下去，所以，这个对概率区间的描述只是近似有效，或者一定时间内有效，由于这个有效时间比较长，所以我们一般仍然使用这种方式来描述，只是在理解上要知道这一点的存在。
（5） 速率斜坡
看到斜坡这种描述词，我们一般会想它是不是一种趋势项。实际上，它确实是趋势性误差，而不是随机误差。所谓随机误差，是指你无法用确定性模型去拟合并消除它，最多只能用概率模型去描述它，这样得到的预测结果也是概率性质的。而趋势性误差是可以直接拟合消除的，在陀螺里，这种误差最常见的原因是温度引起零位变化，可以通过温补来消除。
加速度计同样具有这5项误差，而且原理一致，因此不再重复

2. 惯导误差模型是怎么来的？比如15维的卡尔曼滤波模型。
可参考博客文章 < https://zhuanlan.zhihu.com/p/135230133>
或参考英文文献< Quaternion kinematics for the error-state Kalman filter >

3. GPS双天线安装偏角是怎么标定的？
通过车辆前行得到航迹角，同时双天线自己可以计算出一个航向角，两者之差为安装偏角，具体拟合方法可以通过最小二乘或滤波算出。

4. 多传感器之间是怎么对时的？
激光雷达：大多数雷达如VLP-16等都提供基于pps脉冲和GPRMC信号的输入接口,PPS和GPRMC信号可以由GNSS或IMU提供，或者由外部时钟源提供。少数激光雷达还支持NTP/PTP同步，PTP的精度一般来说比NTP要高，这两个信号都需要由外部时钟源设备提供。
相机：需要支持外部触发曝光的型号，因为相机帧周期包括曝光时间和readout时间（整帧像素点读出），一般来说readout时间是固定的，可以补偿这个时间，相机的时间戳选择为曝光的中间时间。
GNSS：GNSS可以从卫星获得高精度的时钟信号，而且通常的GNSS都支持PPS脉冲以及GPRMC信号。
（1）使用GNSS作为时钟源，将GNSS的PPS信号提供给LiDAR和一个开发板，开发板将给相机同时提供一个曝光的脉冲信号。CAMVOX采用这种方案。
（2）使用外部时钟源，这种时钟源通常支持PPS信号输入，将GNSS的PPS传给外部时钟源，同时外部时钟源可以使用PTP/NTP/PPS给LiDAR做时间同步，同时触发相机开始曝光。外部时钟源同时也可以使用PTP/NTP对主机进行时间同步。

5. GPS到来时是有延时的，而IMU给出的加速度和角速度是实时的，这种情况下怎么处理延时？怎么做的融合？
先通过imu积分计算实时的轨迹，同时把imu数据缓存下来，当GPS到来时，再根据GPS的时间戳去修正历史时刻的数据，然后重新积分该时刻后的imu。

6. DR递推的原理是什么？大概怎么去做？
DR，也叫航位推算，是在知道当前时刻位置的条件下，通过测量移动的距离和方位，推算下一时刻位置的方法。可以根据上一时刻位置速度角度，通过imu加速度二次积分得到平移量，角速度积分得到旋转量来进行DR，也可以通过轮速计和车辆运动模型来进行DR。

7. 组合导航卡尔曼滤波过程噪声是如何调参的？
先通过GPS和imu的性能参数和频率确定一个米级单位下的噪声。之后在该噪声参数下得到融合的轨迹，然后分别对两个噪声增大缩小分成几组进行调节，观察轨迹。最终选最平滑的一组轨迹的噪声参数，或者选跟真值比精度最高的一组的噪声参数 



## 高翔

> source：[想问一下常见SLAM面试编程题？](https://www.zhihu.com/question/532565032/answer/2483264411)

俺举一些自己平时喜欢问的。我比较喜欢问基础问题，所以难度相对低一些：

1. 写一个求两点的距离函数。要求支持常见的2维、3维至任意有限高维点。
2. pose的时间插值是常见需求。写一个6自由度pose的插值函数。pose和时间戳是自定义的结构体，例如 std::vector<TimedPose> 之类。TimedPose.time_stamp为时间，TimedPose.pose是位姿。
3. 让2的函数支持其他的常见有序容器，如std::list<TimedPose>和std::map<double, TimedPose>。
4. 让2的函数支持自定义取时间戳的方式和取pose的方式，因为其他的[结构体](https://www.zhihu.com/search?q=结构体&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2483264411})中时间戳变量和pose变量名称可能不同，例如TimedPose里的时间戳字段是time_stamp，而TimedPose2里的则是time_。
5. 不用库写一个并行的for循环。输入两个[迭代器](https://www.zhihu.com/search?q=迭代器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2483264411})和一个lambda，例如for_each(begin, end, [](int i){cout<<i;});
6. 用你熟悉的优化库写一个自定的edge/factor/residual function。
7. 写一个读取程序，从rosbag中读取给定消息并执行某个回调函数。回调函数由用户定义。
8. 在7的基础上，把读到的消息进行转换，写入另一个bag包。
9. 在8的基础上，把某种常见的操作在一个通用函数内实现。例如，某个msg含有ros标准header的，将它的header.timestamp转成输出消息的timestamp字段。
10. 写一个三维点的operator < 函数。
11. 如何对空间栅格进行hash？写一个存储空间栅格的hash容器。
12. 把一个同步的ros消息处理函数改成异步的。
13. 在10的基础上，支持任意的消息类型和异步回调函数。
14. 用最小二乘写一个由3D点拟合平面参数的函数。
15. 写一个计算某个数组均值和方差的函数。
16. 在14的基础上，支持高维的矢量数组。
17. 在15的基础上，还能支持对任意结构体的某个字段计算均值和方差。
